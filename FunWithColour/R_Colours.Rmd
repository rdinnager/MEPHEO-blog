---
output: 
  html_document:
    self_contained: false
---

It used to be that I would make all my figures in black and white. It was just simpler that way, since most print journals charged extra money to print colour figures, and I did not have any money to spare. But with the move in science publishing from mainly print journals to mainly online (rich) content, colour is no longer a restriction for scientific figure. This is good news because colour can not only make your figures look great, they can help you pack more information into a scientific visualization. But the opposite side of this coin is that if colours are badly chosen, they can make your figure much much worse. This then leads to the question I used to not have to answer: what colours should I use?

I have found several R packages really useful in this regard. `RColorBrewer` is a great package which has a small number of palettes to choose from, but all of them are pre-selected so that their colours will look good together. Recently I have become a fan of the`wesanderson` package by Karthik Ram, which makes available palettes drawn from the wonderfully quirky film canon of the director Wes Anderson. Want your figure to conjure the feeling of "Fantastic Mister Fox"? Or a my personal favourite: "Rushmore" (does that age me?). Just install `wesanderson` and grab the palette! Jo-Fai Chowalso  has an excellent [blog post](http://blenditbayes.blogspot.co.uk/2014/05/towards-yet-another-r-colour-palette.html) with links to more interesting color packages, some of which I have not checked out yet.

But what if I want to get colours that are inspied by any arbitrary image I like, or a non-arbitrary image that may be related to the subject of the figure? I started thinking about this when I had an exchange on twitter with Jo-fai Chow and Karthik Ram, e.g.

<blockquote class="twitter-tweet" data-conversation="none" lang="en"><p><a href="https://twitter.com/_inundata">@_inundata</a> <a href="https://twitter.com/ecologician">@ecologician</a> I&#39;ve been thinking abt a func that loads an img, extracts main colours and arranges them based on colour theory</p>&mdash; Jo-fai Chow (@matlabulous) <a href="https://twitter.com/matlabulous/statuses/469016511517302784">May 21, 2014</a></blockquote>
<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>

Soon thereafter, Jo-fai had already made a basic function, some of which I will steal below:

<blockquote class="twitter-tweet" lang="en"><p><a href="https://twitter.com/ecologician">@ecologician</a> <a href="https://twitter.com/_inundata">@_inundata</a> here is my first attempt - see this gist <a href="http://t.co/2m1XtYTucc">http://t.co/2m1XtYTucc</a></p>&mdash; Jo-fai Chow (@matlabulous) <a href="https://twitter.com/matlabulous/statuses/469499552358473728">May 22, 2014</a></blockquote>
<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>

First a quick function to extract the colours from an online or local image. This code is based on the [`extract_colours()`](https://github.com/woobe/rPlotter/blob/master/R/extract_colours.R) function in the [`rPlotter`](https://github.com/woobe/rPlotter) package written by [Jo-fai Chow](https://github.com/woobe). It uses the [`EBImage`](http://www.bioconductor.org/packages/release/bioc/html/EBImage.html) package to load the image.

```{r colour extract function}
colour_extracter <- function(img_file = "http://developer.r-project.org/Logo/Rlogo-1.png", rsize=100) {
  
  require(EBImage)
  require(reshape2)
  
  ## Read Image
  img <- readImage(img_file)
    
  ## Resize Image (make it smaller so the remaining tasks run faster)  
  if (max(dim(img)[1:2]) > rsize) {
    if (dim(img)[1] > dim(img)[2]) {
      img <- resize(img, w = rsize)
    } else {
      img <- resize(img, h = rsize)
    }
  }
  
  return(img)
}

```

First thing, it would be cool to visualize the distribution of colours in an image to get an idea of where the major colour gradients are. I will use an image of one of my favourite images of one of my favourite animals:

![A posing Peacock Spider](http://upload.wikimedia.org/wikipedia/commons/5/53/MalePeacockSpider.jpg)

This code requires the packages `EBImage`, `reshape2` and `lattice`.

```{r Image colours in Red-Green-Blue space, fig.width=6, fig.height=5, fig.show='animate',cache=TRUE,interval=0.1}
library(EBImage)
library(reshape2)
library(lattice)
## extract the colours!
img<-colour_extracter("http://upload.wikimedia.org/wikipedia/commons/5/53/MalePeacockSpider.jpg",rsize=100)
## reshape
img_melt <- melt(img)
img_rgb <- reshape(img_melt, timevar = "Var3", idvar = c("Var1", "Var2"), direction = "wide")
## get just the colours
spider.cols<-img_rgb[,3:5]
rgbs <- rgb(spider.cols)
## save abundances for later
rgb_dat <- table(rgbs)
## get rid of visually indistinguishable colours
spider.cols <- as.data.frame(t(col2rgb(names(rgb_dat))/255))
colnames(spider.cols) <- c("Red","Green","Blue")
rownames(spider.cols) <- names(rgb_dat)
## plot a spinning 3D plot of the RGB values

for (i in seq(6,360,by=6)) print(cloud(Blue~Red*Green, spider.cols, pch=19, col=rgb(spider.cols), screen=list(z=i,x=-60), perspective=TRUE, scales=list(draw=FALSE), xlab="", ylab="", zlab="", zoom=1, par.settings = list(axis.line = list(col = "transparent"))))

```

This animation gives a nice 'fingerprint' of the images colours. Running down the middle&mdash;along the 1:1:1 line&mdash;are colours with equal red, green, and blue representation, which are colours with low saturation. These tend to be covered up by colour around the outside, so luckily they tend to be the less interesting colours. The brighter, higher saturation colours ring around the low saturation core, and tend to form 'wings' of dominant colours that loop out and along the light to dark axis (the 1:1:1 line). Here we can see one very large wing of red and orangish colours, and a slightly smaller blue wing. Peaking out the bottom is a smaller green wing. 

The question now is how to choose colours from this spectrum that are useful for scientific figures. Well&mdash;to start&mdash; if you are plotting on a white background, you will want to get rid of very light colours. Since I often use `ggplot` and its default light grey background, I don't mind light colours. But I do want to get rid of low saturation colours, both because these are 'greyish' and don't stand out against a grey background, but also because they tend to be visually less appealing when you are plotting in full colour.

One way to get rid of low saturation colours would be to remove any colours whose RGB values that were too close to the 1:1:1 line. But an easier way is to convert your RGB colours into HSV (Hue, Saturation, and Value) colours, and then remove any colours that are below a threshold saturation.

```{r Remove low saturation colours,cache=TRUE}
## convert colours to hsv scale
hsv.col<-t(rgb2hsv(t(spider.cols), maxColorValue = 1))
## remove colours with saturation less than 25%
spider.cols.red<-spider.cols[hsv.col[,"s"]>0.25,]
## plot the result
cloud(Blue~Red*Green, spider.cols.red, pch=19, col=rgb(spider.cols.red), screen=list(z=-45,x=-60), perspective=TRUE, scales = list(col = "black"), par.settings = list(axis.line = list(col = "transparent")))
```

That's better. There is one outlier pixel which is apparent in the above figure. One very bright green out on the upper-left. That is the kind of thing that could fool a clustering algorithm. More on that in a minute.

##What do we want in scientific figure colours?

There is generally two types of palettes we might want to use in a scientific figure

* A palette of contrasting colours, to effectively distinguish between different classes
* A palette consisting of a colour gradient, to effectively represent differing levels of a continuous variable

In this post, I am mostly going to play around with ideas about how to get palette of the first kind from an image of something such as our little spider friend above. The second kind I will cover in a subsequent blog post.

As already mentioned Jo-Fai Chow has already made a function that uses one technique for doing this. Let's try using that on Mr. Peacock:

```{r rPlotter, cache=TRUE, message=FALSE, warning=FALSE}
## install Jo-Fai Chow's package
require(devtools)
install_github("woobe/rPlotter")
library(rPlotter)
## extract 5 colours
pal_spider1 <- extract_colours("http://upload.wikimedia.org/wikipedia/commons/5/53/MalePeacockSpider.jpg")
## plot extracted palette
par(mfrow = c(1,2))
pie(rep(1, 5), col = pal_spider1, main = "Palette based on Peacock Spider")
hist(Nile, breaks = 5, col = pal_spider1, main = "Palette based on Peacock Spider")
```

Jo-Fai Chow's method uses k-means clustering to extract a colour palette. This works by splitting the pixels into _k_ groups based on their similarity in RGB colour space. Once it has found these _k_ clusters, `extract_colours` takes the average colour of each cluster, and returns these cluster averages as the palette. I think this is a great way to it, and offers up a number of ways to tweak the results. For one, there are literally hundreds of methods of performing clustering (k-means is one of the most popular). 

Seeing this method of colour clustering got me thinking about another interesting ways to choose colours from an image. Another major method for clustering is known as "heirarchical clustering", which does not just split the data into _k_ groups but splits the data into an heirarchy of clusters, which can be visualized as a tree. The most similar colours are joined at the tips of the trees, and as you move from the tips to the root, the colours are joined into more inclusive groups. My idea is to apply some methods adapted from the community phylogenetics field (my own field of ecology) to this "colour-tree". First, let's make the colour tree and see what it looks like!

```{r colour clustering 1, cache=TRUE, warning=FALSE, message=FALSE}
library(fastcluster)
library(ape)
## generate a distance matrix from all remaining colours (note: with rsize = 100, this creates a matrix with 38,715,600 elements which takes up about 300mb, be careful if using even greater rsize!)
col_dists<-dist(spider.cols.red)
## use heirarchical scaling to generate a dendrogram of the colours (using UPGMA: "average")
col_clust<-hclust(col_dists, "average")
## convert dendrogram into a phylogenetic tree 
col_tree<-as.phylo(col_clust)
## plot tree!
par(mfrow = c(1,1))
col_tree$tip.label <- rep("_______", length(col_tree$tip.label))
plot(col_tree, show.tip.label=TRUE, type ="fan", no.margin=FALSE, tip.color=rgb(spider.cols.red), underscore=TRUE, cex=1.5)
```

I think the heirarchical clustering causes issues because it forces the resulting distances to be ultrametric (every tree-tip is an equal distance from the tree-root), which probably does not represent colours very well. Instead, let's try neighbour-joining, which simply creates a tree by joining nearest neighbours. 

```{r colour clustering 2, cache=TRUE, warning=FALSE, message=FALSE}
## try using neighbour-joining: this takes much longer!
col_tree2 <- nj(col_dists)
col_tree2$tip.label <- rep("-----", length(col_tree2$tip.label))
plot(col_tree2, show.tip.label=TRUE, type ="fan", no.margin=TRUE, tip.color=rgb(spider.cols.red))
## Another way of visualizing that
plot(col_tree2, show.tip.label=FALSE, type ="unrooted", no.margin=TRUE)
tiplabels(pch=19, col = rgb(spider.cols.red), cex=0.7)
```

Looks good! But we immediately start to see a problem by visualizing the colours like this. For one, the blueish colours have large branch-lengths, yet they appear to all be very similar, at least to my eye. It turns out that human colour perception is quite biased with regards to certain hues. For example blue hues are difficult to distinguish by eye, such that some colours that are very different in RGB space can appear quite similar. On the other hand, red and orangish hues can appear quite different, despite being very close in RGB space. To account for this, other colorspaces have been developed which attempt to get closer to how humans percieve colours. An example of this is the [CIELAB](http://en.wikipedia.org/wiki/Lab_color_space) colorspace, or L\*A\*B\* for short. This space consists of three dimensions. The first, known as __L\*__ corresponds to luminosity, and is a very good measure of how humans percieved light cs. dark. __L\*__ ranges between 0 and 100, with high values being light colours. The other two elements are __a\*__ and __b\*__, which are the position of the colour on the red/magenta to green scale (-100 to 100), and the blue to yellow scale (-100 to 100), respectively. I therefore decided to transform the image's colours to CIELAB space using the `colorspace` package before analyzing further:

```{r colourspace, cache=TRUE, message=FALSE, warning=FALSE}
library(colorspace)
spider.cols.LAB <- as(RGB(as.matrix(spider.cols.red)), "LAB")
spider.cols.LAB <- as.data.frame(coords(spider.cols.LAB))
cloud(L~A*B, spider.cols.LAB, pch=19, col=rownames(spider.cols.LAB), screen=list(z=-45,x=-60), perspective=TRUE, scales = list(col = "black"), par.settings = list(axis.line = list(col = "transparent")))
col_dists_LAB <- dist(spider.cols.LAB)
col_tree_LAB <- nj(col_dists_LAB)
col_tree_LAB$tip.label <- rep("_________", length(col_tree_LAB$tip.label))
plot(col_tree_LAB, show.tip.label=TRUE, type ="fan", no.margin=TRUE, tip.color=rgb(spider.cols.red),
     underscore=TRUE)
## compare with RGB
par(mfrow = c(1,2), mar=c(2,2,2,2))
plot(col_tree2, show.tip.label=FALSE, type ="unrooted", no.margin=FALSE, main = "RGB")
tiplabels(pch=19, col = rgb(spider.cols.red), cex=0.7)
plot(col_tree_LAB, show.tip.label=FALSE, type ="unrooted", no.margin=FALSE, main = "L*A*B*")
tiplabels(pch=19, col = rgb(spider.cols.red), cex=0.7)
par(mfrow = c(1,1))
```

In the new colorspace, we can see that the blue hues now take up a much smaller volume, reflecting human's poor ability to distinguish these hues. On the other hand the red and orange hues have expanded to fill more space.

```{r find colours, cache=TRUE, message=FALSE, warning=FALSE}
library(picante)
## number of colours to extract
ncolours <- 10
col_samp <- t(replicate(10000, as.numeric((rownames(spider.cols.LUV) %in% sample(rownames(spider.cols.LUV),ncolours)))))
colnames(col_samp) <- rownames(spider.cols.LUV)
col_mpd <- mpd(col_samp, as.matrix(col_dists_LUV))
col_best <- colnames(col_samp)[col_samp[which.max(col_mpd),]==1]
pie(rep(1, ncolours), col = col_best, main = "Palette based on Peacock Spider")
```

```{r testing, cache=TRUE, eval=FALSE}
spider.cols.LUV <- as(RGB(as.matrix(spider.cols.red)), "LUV")
spider.cols.LUV <- as.data.frame(coords(spider.cols.LUV))
cloud(L~U*V, spider.cols.LUV, pch=19, col=rownames(spider.cols.LUV), screen=list(z=-45,x=-60), perspective=TRUE, scales = list(col = "black"), par.settings = list(axis.line = list(col = "transparent")))
col_dists_LUV <- dist(spider.cols.LUV)
col_tree_LUV <- nj(col_dists_LUV)
col_tree_LUV$tip.label <- rep("_________", length(col_tree_LUV$tip.label))
plot(col_tree_LUV, show.tip.label=TRUE, type ="fan", no.margin=TRUE, tip.color=rgb(spider.cols.red),
     underscore=TRUE)
plot(col_tree_LUV, show.tip.label=FALSE, type ="unrooted", no.margin=TRUE)
tiplabels(pch=19, col = rgb(spider.cols.red), cex=0.7)
```

